绪论

1.背景

随着信息产业革命的不断演进，互联网愈发深刻地影响着现实社会，并衍生出社交网络，物联网，O2O（线上到线下），共享经济等全新的连接人与人，人与物，人与服务的方式甚至全新的人类合作模式。在此过程中，这些全新的应用既对我们如何有效处理人类最熟悉的信息表达手段————自然语言提出了全新的挑战；也为自然语言处理技术的发展提供了应用平台和海量语料。

过去几年机器学习方法在天气预测，金融策略和个性化广告方面的成功教育了市场，让寂静了多年的人工智能领域回暖升温。尤其是媒体对深度学习技术的炒作更点燃了公众的热情。市场上对真正可用的智能的个人助理，问答系统，甚至是虚拟家教等需要较强AI技术的产品存在着很高的呼声。这对发展更强的自然语言处理技术，尤其是语义理解技术和知识的获取表示与学习技术，提出了迫切的需求。

另一方面，随着技术的发展，尤其是较廉价的高性能运算加速硬件GPU的广泛应用，神经网络模型又一次站到了学术圈和公众舆论的风口浪尖。以超强计算能力支持的深度学习模型对比机器学习模型，在一系列任务上取得了惊人的性能提升。如在语音识别领域，在2012年深度神经网络将错误率历史性地降低到16%[2],这促使国外的谷歌，苹果和国内的百度，科大讯分等公司开发一系列以深度学习模型为基础的语音服务产品。又如在计算机视觉领域，2012年Hinton参加ImageNet比赛[3]，使用深度神经网络以领先第二名传统方法10%的成绩获得冠军[1]。这同样促使百度，谷歌等公司在其搜索业务中跟进，提高了其图像搜索的准确度。值得一提的是，在深度学习专家Yann LeCun的帮助下，Facebook AI实验室的人脸识别系统已经达到和人类能力相似的水平[4]。这一研究成果被广泛应用在facebook的社交产品中，产生巨大的经济效益。


在语音识别和计算机视觉两个输入信号抽象层次较低的领域取得较大成功后，深度学习又继续进军自然语言处理领域。深度学习巨头之一Hinton就在2015年在Nature上撰文表示未来几年深度学习会在自然语言处理领域产生巨大的影响。[5]

总地来说，面对着传统互联网和移动互联网提供的海量语料，语义关系的自动挖掘是充分利用这些资源开发自动知识库构建系统的一个必要的子任务；移动互联网全面渗透进入人类生活的新的经济形势也给广义上语义计算任务提出了更高书评的要求。紧跟学术界前沿的动态，采用神经网络方法进行领域实体语义关系分类这一任务的研究，既有重要的现实应用，又有较大的学术潜力。在研究过程中实现的现有方法或演化出的新方法也有着转移到其他自然语言处理任务上的可能性。这个题目具有现实和学术的双重意义。

2.研究现状

深度学习应用于自然语言处理任务

实际上，深度学习方法在自然语言处理领域已经有很大建树，这些成果在一定程度上改变了自然语言处理问题的基本方法。如2003年，Bengio等人使用三层的auto-encoder对n-gram模型进行建模，得到word embedding。[o16]word embedding又称词的distributed representation，这是一种蕴含语义信息的稠密向量表示。和传统的onehot vector相比，这种新的词表示方法同时具有维度低和语义含义丰富两个特征。这一成果解决了语言信息在神经网络中没有恰当的抽象表示的问题。

具体来说，Bengio假设一个词的context暗示了这个词的语义；在语料库中拥有相似context分布的词有相似的语义。word embedding得到了一个从离散的词集合到连续的固定维度向量集合的映射，在映射后的向量空间空间中词向量之间有着良好的性质：语义相似的词向量距离更近；词向量之间的差描述了语义的区别。

值得庆幸的是，wording embedding的训练是一个无监督问题，可以在未经标注的庞大语料库上进行训练；和传统使用树库等有监督训练方面的工作相比，在语料来源的广泛程度和容易程度上有着巨大的优势。

word embedding在自然语言处理问题上已经得到了广泛且高质量的应用。如
