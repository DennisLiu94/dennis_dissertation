绪论

1.背景

随着信息产业革命的不断演进，互联网愈发深刻地影响着现实社会，并衍生出社交网络，物联网，O2O（线上到线下），共享经济等全新的连接人与人，人与物，人与服务的方式甚至全新的人类合作模式。在此过程中，这些全新的应用既对我们如何有效处理人类最熟悉的信息表达手段————自然语言提出了全新的挑战；也为自然语言处理技术的发展提供了应用平台和海量语料。

过去几年机器学习方法在天气预测，金融策略和个性化广告方面的成功教育了市场，让寂静了多年的人工智能领域回暖升温。尤其是媒体对深度学习技术的炒作更点燃了公众的热情。市场上对真正可用的智能的个人助理，问答系统，甚至是虚拟家教等需要较强AI技术的产品存在着很高的呼声。这对发展更强的自然语言处理技术，尤其是语义理解技术和知识的获取表示与学习技术，提出了迫切的需求。

另一方面，随着技术的发展，尤其是较廉价的高性能运算加速硬件GPU的广泛应用，神经网络模型又一次站到了学术圈和公众舆论的风口浪尖。以超强计算能力支持的深度学习模型对比机器学习模型，在一系列任务上取得了惊人的性能提升。如在语音识别领域，在2012年深度神经网络将错误率历史性地降低到16%[2],这促使国外的谷歌，苹果和国内的百度，科大讯分等公司开发一系列以深度学习模型为基础的语音服务产品。又如在计算机视觉领域，2012年Hinton参加ImageNet比赛[3]，使用深度神经网络以领先第二名传统方法10%的成绩获得冠军[1]。这同样促使百度，谷歌等公司在其搜索业务中跟进，提高了其图像搜索的准确度。值得一提的是，在深度学习专家Yann LeCun的帮助下，Facebook AI实验室的人脸识别系统已经达到和人类能力相似的水平[4]。这一研究成果被广泛应用在facebook的社交产品中，产生巨大的经济效益。


在语音识别和计算机视觉两个输入信号抽象层次较低的领域取得较大成功后，深度学习又继续进军自然语言处理领域。深度学习巨头之一Hinton就在2015年在Nature上撰文表示未来几年深度学习会在自然语言处理领域产生巨大的影响。[5]

实际上，深度学习方法在自然语言处理领域已经有很大建树，这些成果在一定程度上改变了自然语言处理问题的基本方法。如2003年，Bengio等人使用三层的auto-encoder对n-gram模型进行建模，得到word embedding。[o16]word embedding又称词的distributed representation，这是一种蕴含语义信息的稠密向量表示。和传统的onehot vector相比，这种新的词表示方法
